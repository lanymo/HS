# README.md

## 핵심 내용 정리

### RAG(Retrieval-Augmented Generation) 개념

1. **기본 원리**: 질문에 관련된 정보를 외부 데이터베이스에서 검색하여 LLM의 컨텍스트로 제공합니다.
2. **장점**:
    - 최신 정보 반영 가능
    - 특정 도메인에 대한 전문성 향상
    - 소스 추적 가능성 제공
3. **구현 방식**:
    - 기본 RAG
    - 다중 쿼리 RAG
    - 재귀적 RAG
    - 에이전트 기반 RAG

### 프로젝트 구현 세부사항

1. **데이터 수집 및 전처리**:
    - 사용한 데이터 소스:
    - 전처리 방법:
2. **벡터 데이터베이스**:
    - 사용한 벡터 데이터베이스:
    - 인덱싱 방법:
3. **RAG 파이프라인**:
    - 선택한 RAG 방식:
    - 구현 세부사항:
4. **프롬프트 엔지니어링**:
    - 설계한 프롬프트 구조:
    - 최적화 전략:
5. **평가 및 최적화**:
    - 평가 메트릭:
    - 최적화 과정:

## 향후 개선 방향

- 
- 
- 

## 결과 및 성능

- 정확성:
- 관련성:
- 일관성:

## 사용 기술 및 도구

- 
- 
- 

## 팀 구성 및 역할

- 
- 
- 

## 추가 고려사항 (Optional)

### 실시간 성능

- RAG 시스템의 평균 응답 시간:
- 성능 최적화 전략:

### 확장성

- 다양한 주제 처리 능력:
- 스케일링 전략:

### 설명 가능성

- 정보 선택 이유 설명 방법:
- 투명성 향상 전략:

### 관련 논문 리뷰

- 논문 리스트
    - "Retrieval-Augmented Generation for Knowledge-Intensive NLP Tasks" (2020)
        - RAG의 기본 개념을 소개한 원본 논문
        - https://arxiv.org/abs/2005.11401
    - "Self-RAG: Learning to Retrieve, Generate, and Critique through Self-Reflection" (2023)
        - RAG 시스템의 자가 개선 방법을 제시
        - https://arxiv.org/abs/2310.11511
    - "REPLUG: Retrieval-Augmented Black-Box Language Models" (2023)
        - 블랙박스 LLM에 RAG를 적용하는 방법 제안
        - https://arxiv.org/abs/2301.12652
    - "Chain-of-Note: Enhancing Robustness in Retrieval-Augmented Language Models" (2023)
        - RAG의 견고성을 높이는 새로운 접근법 제시
        - https://arxiv.org/abs/2311.09210
    - "Benchmarking Large Language Models for News Summarization" (2023)
        - LLM의 할루시네이션 문제를 다루며, RAG의 효과성을 검증
        - https://arxiv.org/abs/2301.13848
    - "RAFT: Adapting Language Model to Domain Specific RAG" (2023)
        - 특정 도메인에 RAG를 적용하는 방법 제안
        - https://arxiv.org/abs/2309.11733
    - "In-Context Retrieval-Augmented Language Models" (2023)
        - RAG를 인-컨텍스트 학습과 결합하는 방법 제시
        - https://arxiv.org/abs/2302.00083
1. [논문 제목](논문 링크)
    - 핵심 아이디어:
    - 본 프로젝트에 적용한 점:
